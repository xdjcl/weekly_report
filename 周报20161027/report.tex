\documentclass{ctexart}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{hyperref}
\usepackage{subfigure}
\usepackage{geometry}
\geometry{left=2.5cm,right=3.5cm,top=2.5cm,bottom=2.5cm}
\CTEXsetup[format+={\flushleft}]{section}

\begin{document}
\CJKfamily{li}
\title{周报}
\author{刘精昌}
\maketitle
\fangsong

\section*{本周工作}
\begin{enumerate}
  \item Boyd《Convex Optimization》1、2章以及Parikh, Boyd《Proximal Algorithms》1、2、3、4节，《Proximal Algorithms》介绍优化方面的Proximal算法特别详细，阅读收获很大。
  \item 对于《Asynchronous Multi-Task Learning》和《Make Workers Work Harder: Decoupled Asynchronous Proximal Stochastic Gradient Descent》，两者都意在解决\[\mathop {\min }\limits_x \left\{ {\sum\limits_{i = 1}^T {\mathop f\nolimits_t \left( {\mathop x\nolimits_t } \right) + \lambda g\left( x \right)} } \right\} \equiv f\left( x \right) + \lambda g\left( x \right)\]， 这种形式的问题，可以用如下的prox迭代式进行求解：
      \[{x_{t + 1}} = \mathop {Prox}\nolimits_{\mathop \eta \nolimits_t ,g} \left( {{x_t} - \mathop \eta \nolimits_t \nabla f\left( {\mathop x\nolimits_t } \right)} \right)\]
      李亦锬的论文首先介绍了在原始迭代式中加上随机化的随机prox迭代: \[{x_{t + 1}} = Pro{x_{{\eta _t},g}}\left( {{x_t} - {\eta _t}\nabla {f_t}\left( {{\rm{ }}{x_t}} \right)} \right)\]
      这种迭代式能够满足异步的需求： 客户机计算${{f_t}\left( {{\rm{ }}{x_t}} \right)}$的梯度，计算完毕之后返回给 服务器，由服务器进行prox操作。但是prox计算复杂，耗费服务器资源，于是该文提出了一个简单的改进：客户端返回服务器的是参数的update信息，即客户端进行prox操作，计算得到$d_{t+1}$步参数值，并将与$d_{t}$步的差返回服务器，服务器把这个差作为$t$步的增量。


      ${x_{t + 1}} = \mathop {Prox}\nolimits_{\mathop \eta \nolimits_t ,g} \left( {{x_t} - \mathop \eta \nolimits_t \nabla f\left( {\mathop x\nolimits_t } \right)} \right)$等价于${x_{t + 1}} = {\left( {I + \mathop \eta \nolimits_t g\left(  \right)} \right)^{ - 1}}\left( {I - \eta \nabla f} \right)\left( {{x_t}} \right)$（Boyd书中有讲），我疑惑的是本来可以直接用随机prox来进行异步，《Asynchronous Multi-Task Learning》作者却说这种情况不能异步，而是变成下面的情况：
      \[{v_{t + 1}} = \left( {I - \eta \nabla \mathop f\nolimits_t } \right){\left( {{{\left( {I + \eta g\left(  \right)} \right)}^{ - 1}}\left( V \right)} \right)_t}\]
      ${{{\left( {I + \eta g\left(  \right)} \right)}^{ - 1}}}$等价于${prox}_{\eta ,g}$，服务器进行prox操作，返给客户端，计算梯度。
\end{enumerate}

\section*{下周计划}
\begin{itemize}
  \item 继续看Boyd的资料为主。
\end{itemize}
\end{document} 