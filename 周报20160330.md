### 继续阅读周志华《机器学习》，并做了后面的习题。

### 学习了一些常用的不等式，比如：Cauchy-Schwarz、Holder、Minkowski、Markov、Hoeffding。

### 阅读《Time Series Shapelets: A New Primitive for Data Mining》.kdd09
该文提出了一种新的基于特征选择的序列分类方法。shapelets是序列中最能够代表某类序列特征的小片段。shapelets是从所有序列子序列组成的候选集中得到，原则是序列集合的信息增益最大化。信息增益的即熵的变化，集合D的熵的定义是：
> 对于时间序列集合D，包括两类A、B，比例分别为p(A),p(B)，熵：-p(A)log(p(A))-p(B)log(p(B))

定义D为训练集，是序列集合，对于候选集中某一序列S，信息增益的计算算法是：
1. 计算S与D中所有序列之间的距离（依照序列距离的定义）。
2. 对于某距离阈值，依照计算得到的距离和阈值的大小关系，对D划分，使得划分前后熵的变化最大。这时的熵的变化即为信息增益，阈值即为最优阈值。

候选集中信息增益最大的子序列即为shapelets。

直观上看，信息增益即是训练集中不同类的分离程度变化的度量，shapelets即最能够分开训练集中不同类的子序列，它和训练集的某一类相近，而和另一类相远。

对于测试集，可以根据其和shapelets的亲疏，对其分类。

此外，在求解shapelets时，利用小技巧，能够加快shapelets的计算：
* 在求解最大信息增益时，可以将目前已知的最大信息增益记录下来。在后续的信息增益计算中，考虑最极端的信息增益情况，若没有已知的最大信息增益大，那么这步的计算就能中断了。

最后，作者通过其大量的实践，论证了shapelets方法在分类方面的优秀性。

$ \frac{1}{n} $
